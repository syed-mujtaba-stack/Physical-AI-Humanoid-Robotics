"use strict";(globalThis.webpackChunktextbook_frontend=globalThis.webpackChunktextbook_frontend||[]).push([[8295],{7717:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>t,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"chapter-07-vslam","title":"Chapter 7: VSLAM & Navigation with Nav2","description":"Learning Objectives","source":"@site/docs/chapter-07-vslam.md","sourceDirName":".","slug":"/chapter-07-vslam","permalink":"/Physical-AI-Humanoid-Robotics/docs/chapter-07-vslam","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chapter-07-vslam.md","tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_position":8},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 6: NVIDIA Isaac Sim - The Ultimate Robot Simulator","permalink":"/Physical-AI-Humanoid-Robotics/docs/chapter-06-isaac-sim"},"next":{"title":"Chapter 8: Vision-Language-Action (VLA) Models","permalink":"/Physical-AI-Humanoid-Robotics/docs/chapter-08-vla"}}');var i=r(4848),s=r(8453);const l={sidebar_position:8},o="Chapter 7: VSLAM & Navigation with Nav2",t={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"What is SLAM?",id:"what-is-slam",level:2},{value:"Types of SLAM",id:"types-of-slam",level:3},{value:"Visual SLAM Fundamentals",id:"visual-slam-fundamentals",level:2},{value:"Key Components",id:"key-components",level:3},{value:"ORB-SLAM3",id:"orb-slam3",level:3},{value:"Nav2: The ROS 2 Navigation Stack",id:"nav2-the-ros-2-navigation-stack",level:2},{value:"Architecture",id:"architecture",level:3},{value:"Key Components",id:"key-components-1",level:3},{value:"Installing Nav2",id:"installing-nav2",level:2},{value:"Configuring Nav2 for Humanoids",id:"configuring-nav2-for-humanoids",level:2},{value:"Challenge: Bipedal Locomotion",id:"challenge-bipedal-locomotion",level:3},{value:"Costmap Configuration",id:"costmap-configuration",level:3},{value:"Planner Configuration",id:"planner-configuration",level:3},{value:"Controller Configuration",id:"controller-configuration",level:3},{value:"Behavior Trees for Navigation",id:"behavior-trees-for-navigation",level:2},{value:"Lab Exercise: Mapping a Room with VSLAM",id:"lab-exercise-mapping-a-room-with-vslam",level:2},{value:"Objective",id:"objective",level:3},{value:"Step 1: Launch Simulation",id:"step-1-launch-simulation",level:3},{value:"Step 2: Launch ORB-SLAM3",id:"step-2-launch-orb-slam3",level:3},{value:"Step 3: Teleoperate Robot",id:"step-3-teleoperate-robot",level:3},{value:"Step 4: Save Map",id:"step-4-save-map",level:3},{value:"Lab Exercise: Autonomous Navigation",id:"lab-exercise-autonomous-navigation",level:2},{value:"Step 1: Launch Nav2",id:"step-1-launch-nav2",level:3},{value:"Step 2: Set Initial Pose in RViz",id:"step-2-set-initial-pose-in-rviz",level:3},{value:"Step 3: Set Navigation Goal",id:"step-3-set-navigation-goal",level:3},{value:"Quiz",id:"quiz",level:2},{value:"Summary",id:"summary",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"chapter-7-vslam--navigation-with-nav2",children:"Chapter 7: VSLAM & Navigation with Nav2"})}),"\n",(0,i.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Understand SLAM (Simultaneous Localization and Mapping)"}),"\n",(0,i.jsx)(n.li,{children:"Implement Visual SLAM using cameras"}),"\n",(0,i.jsx)(n.li,{children:"Master the Nav2 stack for autonomous navigation"}),"\n",(0,i.jsx)(n.li,{children:"Configure costmaps and planners for humanoid robots"}),"\n",(0,i.jsx)(n.li,{children:"Implement behavior trees for complex navigation tasks"}),"\n",(0,i.jsx)(n.li,{children:"Deploy navigation on a simulated humanoid"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"what-is-slam",children:"What is SLAM?"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"SLAM"})," solves the chicken-and-egg problem:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Localization"}),": Where am I? (requires a map)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Mapping"}),": What does the environment look like? (requires knowing where you are)"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"SLAM solves both simultaneously."}),"\n",(0,i.jsx)(n.h3,{id:"types-of-slam",children:"Types of SLAM"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Type"}),(0,i.jsx)(n.th,{children:"Sensors"}),(0,i.jsx)(n.th,{children:"Use Case"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"LiDAR SLAM"})}),(0,i.jsx)(n.td,{children:"2D/3D LiDAR"}),(0,i.jsx)(n.td,{children:"Indoor navigation, warehouses"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Visual SLAM (VSLAM)"})}),(0,i.jsx)(n.td,{children:"Cameras (mono/stereo)"}),(0,i.jsx)(n.td,{children:"Drones, humanoids"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"RGB-D SLAM"})}),(0,i.jsx)(n.td,{children:"Depth cameras (RealSense)"}),(0,i.jsx)(n.td,{children:"Indoor robots"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Inertial SLAM"})}),(0,i.jsx)(n.td,{children:"IMU + Camera"}),(0,i.jsx)(n.td,{children:"High-speed motion"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"For humanoids"}),": VSLAM is preferred (lightweight, human-like perception)."]}),"\n",(0,i.jsx)(n.h2,{id:"visual-slam-fundamentals",children:"Visual SLAM Fundamentals"}),"\n",(0,i.jsx)(n.h3,{id:"key-components",children:"Key Components"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Feature Detection"}),": Identify keypoints in images (SIFT, ORB, FAST)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Feature Matching"}),": Match keypoints across frames"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Motion Estimation"}),": Calculate camera movement (Visual Odometry)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Loop Closure"}),": Recognize revisited locations to correct drift"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Bundle Adjustment"}),": Optimize camera poses and 3D points"]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-mermaid",children:"graph LR\r\n    A[Camera Image] --\x3e B[Feature Detection]\r\n    B --\x3e C[Feature Matching]\r\n    C --\x3e D[Motion Estimation]\r\n    D --\x3e E[Map Update]\r\n    E --\x3e F{Loop Detected?}\r\n    F --\x3e|Yes| G[Bundle Adjustment]\r\n    F --\x3e|No| D\r\n    G --\x3e E\n"})}),"\n",(0,i.jsx)(n.h3,{id:"orb-slam3",children:"ORB-SLAM3"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"ORB-SLAM3"})," is the state-of-the-art open-source VSLAM system."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Features"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Monocular, stereo, RGB-D support"}),"\n",(0,i.jsx)(n.li,{children:"IMU fusion"}),"\n",(0,i.jsx)(n.li,{children:"Multi-map support"}),"\n",(0,i.jsx)(n.li,{children:"Real-time performance"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Installation"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws/src\r\ngit clone https://github.com/UZ-SLAMLab/ORB_SLAM3.git\r\ncd ORB_SLAM3\r\nchmod +x build.sh\r\n./build.sh\r\n\r\n# ROS 2 wrapper\r\ncd ~/ros2_ws/src\r\ngit clone https://github.com/zang09/ORB_SLAM3_ROS2.git\r\ncd ~/ros2_ws\r\ncolcon build --packages-select orb_slam3_ros2\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Running ORB-SLAM3"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 run orb_slam3_ros2 mono \\\r\n    /path/to/ORBvoc.txt \\\r\n    /path/to/camera_config.yaml\n"})}),"\n",(0,i.jsx)(n.h2,{id:"nav2-the-ros-2-navigation-stack",children:"Nav2: The ROS 2 Navigation Stack"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Nav2"})," is the successor to ROS 1's navigation stack, designed for production robots."]}),"\n",(0,i.jsx)(n.h3,{id:"architecture",children:"Architecture"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-mermaid",children:"graph TD\r\n    A[Goal Pose] --\x3e B[Planner Server]\r\n    B --\x3e C[Global Path]\r\n    C --\x3e D[Controller Server]\r\n    D --\x3e E[Local Path]\r\n    E --\x3e F[cmd_vel]\r\n    F --\x3e G[Robot]\r\n    G --\x3e H[Sensors]\r\n    H --\x3e I[Costmap]\r\n    I --\x3e B\r\n    I --\x3e D\n"})}),"\n",(0,i.jsx)(n.h3,{id:"key-components-1",children:"Key Components"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Component"}),(0,i.jsx)(n.th,{children:"Function"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Planner Server"})}),(0,i.jsx)(n.td,{children:"Computes global path (A*, Dijkstra, Theta*)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Controller Server"})}),(0,i.jsx)(n.td,{children:"Follows path (DWB, TEB, MPPI)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Costmap 2D"})}),(0,i.jsx)(n.td,{children:"Represents obstacles and free space"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Behavior Trees"})}),(0,i.jsx)(n.td,{children:"High-level task logic"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Recovery Behaviors"})}),(0,i.jsx)(n.td,{children:"Handle failures (rotate, back up)"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"installing-nav2",children:"Installing Nav2"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"sudo apt install ros-humble-navigation2 ros-humble-nav2-bringup\n"})}),"\n",(0,i.jsx)(n.h2,{id:"configuring-nav2-for-humanoids",children:"Configuring Nav2 for Humanoids"}),"\n",(0,i.jsx)(n.h3,{id:"challenge-bipedal-locomotion",children:"Challenge: Bipedal Locomotion"}),"\n",(0,i.jsx)(n.p,{children:"Unlike wheeled robots, humanoids:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Have a ",(0,i.jsx)(n.strong,{children:"smaller footprint"})," (two feet)"]}),"\n",(0,i.jsxs)(n.li,{children:["Require ",(0,i.jsx)(n.strong,{children:"dynamic balance"})," (can't stop instantly)"]}),"\n",(0,i.jsxs)(n.li,{children:["Need ",(0,i.jsx)(n.strong,{children:"step planning"})," (not continuous motion)"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"costmap-configuration",children:"Costmap Configuration"}),"\n",(0,i.jsxs)(n.p,{children:["Create ",(0,i.jsx)(n.code,{children:"nav2_params.yaml"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'costmap_2d:\r\n  global_costmap:\r\n    global_frame: map\r\n    robot_base_frame: base_link\r\n    update_frequency: 1.0\r\n    publish_frequency: 1.0\r\n    width: 50\r\n    height: 50\r\n    resolution: 0.05\r\n    robot_radius: 0.15  # Humanoid footprint\r\n    plugins: ["static_layer", "obstacle_layer", "inflation_layer"]\r\n    \r\n    static_layer:\r\n      plugin: "nav2_costmap_2d::StaticLayer"\r\n      map_subscribe_transient_local: True\r\n    \r\n    obstacle_layer:\r\n      plugin: "nav2_costmap_2d::ObstacleLayer"\r\n      observation_sources: scan\r\n      scan:\r\n        topic: /scan\r\n        max_obstacle_height: 2.0\r\n        clearing: True\r\n        marking: True\r\n    \r\n    inflation_layer:\r\n      plugin: "nav2_costmap_2d::InflationLayer"\r\n      cost_scaling_factor: 3.0\r\n      inflation_radius: 0.55\r\n\r\n  local_costmap:\r\n    global_frame: odom\r\n    robot_base_frame: base_link\r\n    update_frequency: 5.0\r\n    publish_frequency: 2.0\r\n    width: 3\r\n    height: 3\r\n    resolution: 0.05\r\n    robot_radius: 0.15\r\n    plugins: ["obstacle_layer", "inflation_layer"]\n'})}),"\n",(0,i.jsx)(n.h3,{id:"planner-configuration",children:"Planner Configuration"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'planner_server:\r\n  ros__parameters:\r\n    expected_planner_frequency: 20.0\r\n    planner_plugins: ["GridBased"]\r\n    GridBased:\r\n      plugin: "nav2_navfn_planner/NavfnPlanner"\r\n      tolerance: 0.5\r\n      use_astar: false  # Dijkstra for safety\r\n      allow_unknown: true\n'})}),"\n",(0,i.jsx)(n.h3,{id:"controller-configuration",children:"Controller Configuration"}),"\n",(0,i.jsxs)(n.p,{children:["For humanoids, use ",(0,i.jsx)(n.strong,{children:"Model Predictive Path Integral (MPPI)"})," controller:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yaml",children:'controller_server:\r\n  ros__parameters:\r\n    controller_frequency: 20.0\r\n    controller_plugins: ["FollowPath"]\r\n    FollowPath:\r\n      plugin: "nav2_mppi_controller::MPPIController"\r\n      time_steps: 56\r\n      model_dt: 0.05\r\n      batch_size: 2000\r\n      vx_std: 0.2\r\n      vy_std: 0.2\r\n      wz_std: 0.4\r\n      vx_max: 0.5  # Humanoid walking speed\r\n      vx_min: -0.35\r\n      vy_max: 0.5\r\n      wz_max: 1.9\n'})}),"\n",(0,i.jsx)(n.h2,{id:"behavior-trees-for-navigation",children:"Behavior Trees for Navigation"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Behavior Trees"})," (BT) allow complex decision-making."]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Example: Navigate with Recovery"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<root main_tree_to_execute="MainTree">\r\n  <BehaviorTree ID="MainTree">\r\n    <RecoveryNode number_of_retries="6" name="NavigateRecovery">\r\n      <PipelineSequence name="NavigateWithReplanning">\r\n        <RateController hz="1.0">\r\n          <RecoveryNode number_of_retries="1" name="ComputePathToPose">\r\n            <ComputePathToPose goal="{goal}" path="{path}" planner_id="GridBased"/>\r\n            <ClearEntireCostmap name="ClearGlobalCostmap-Context" service_name="global_costmap/clear_entirely_global_costmap"/>\r\n          </RecoveryNode>\r\n        </RateController>\r\n        <RecoveryNode number_of_retries="1" name="FollowPath">\r\n          <FollowPath path="{path}" controller_id="FollowPath"/>\r\n          <ClearEntireCostmap name="ClearLocalCostmap-Context" service_name="local_costmap/clear_entirely_local_costmap"/>\r\n        </RecoveryNode>\r\n      </PipelineSequence>\r\n      <SequenceStar name="RecoveryActions">\r\n        <ClearEntireCostmap name="ClearLocalCostmap-Subtree" service_name="local_costmap/clear_entirely_local_costmap"/>\r\n        <ClearEntireCostmap name="ClearGlobalCostmap-Subtree" service_name="global_costmap/clear_entirely_global_costmap"/>\r\n        <Spin spin_dist="1.57"/>\r\n        <Wait wait_duration="5"/>\r\n      </SequenceStar>\r\n    </RecoveryNode>\r\n  </BehaviorTree>\r\n</root>\n'})}),"\n",(0,i.jsx)(n.h2,{id:"lab-exercise-mapping-a-room-with-vslam",children:"Lab Exercise: Mapping a Room with VSLAM"}),"\n",(0,i.jsx)(n.h3,{id:"objective",children:"Objective"}),"\n",(0,i.jsx)(n.p,{children:"Use a simulated humanoid with a camera to build a map of a room."}),"\n",(0,i.jsx)(n.h3,{id:"step-1-launch-simulation",children:"Step 1: Launch Simulation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 launch humanoid_gazebo world.launch.py\n"})}),"\n",(0,i.jsx)(n.h3,{id:"step-2-launch-orb-slam3",children:"Step 2: Launch ORB-SLAM3"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 run orb_slam3_ros2 mono \\\r\n    ~/ORB_SLAM3/Vocabulary/ORBvoc.txt \\\r\n    ~/config/camera.yaml\n"})}),"\n",(0,i.jsx)(n.h3,{id:"step-3-teleoperate-robot",children:"Step 3: Teleoperate Robot"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 run teleop_twist_keyboard teleop_twist_keyboard\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Task"}),": Drive the robot around the room to build a map."]}),"\n",(0,i.jsx)(n.h3,{id:"step-4-save-map",children:"Step 4: Save Map"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 run nav2_map_server map_saver_cli -f my_room_map\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Output"}),": ",(0,i.jsx)(n.code,{children:"my_room_map.pgm"})," (image) and ",(0,i.jsx)(n.code,{children:"my_room_map.yaml"})," (metadata)."]}),"\n",(0,i.jsx)(n.h2,{id:"lab-exercise-autonomous-navigation",children:"Lab Exercise: Autonomous Navigation"}),"\n",(0,i.jsx)(n.h3,{id:"step-1-launch-nav2",children:"Step 1: Launch Nav2"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 launch nav2_bringup bringup_launch.py \\\r\n    map:=my_room_map.yaml \\\r\n    params_file:=nav2_params.yaml\n"})}),"\n",(0,i.jsx)(n.h3,{id:"step-2-set-initial-pose-in-rviz",children:"Step 2: Set Initial Pose in RViz"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Open RViz: ",(0,i.jsx)(n.code,{children:"ros2 run rviz2 rviz2"})]}),"\n",(0,i.jsx)(n.li,{children:'Click "2D Pose Estimate"'}),"\n",(0,i.jsx)(n.li,{children:"Click on the map where the robot is"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"step-3-set-navigation-goal",children:"Step 3: Set Navigation Goal"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:'Click "2D Goal Pose"'}),"\n",(0,i.jsx)(n.li,{children:"Click on the map where you want the robot to go"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Expected"}),": Robot plans a path and navigates autonomously."]}),"\n",(0,i.jsx)(n.h2,{id:"quiz",children:"Quiz"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"What does SLAM stand for?"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A) Simultaneous Laser and Mapping"}),"\n",(0,i.jsx)(n.li,{children:"B) Simultaneous Localization and Mapping"}),"\n",(0,i.jsx)(n.li,{children:"C) Sensor Localization and Movement"}),"\n",(0,i.jsx)(n.li,{children:"D) Spatial Learning and Memory"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Answer: B"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Which sensor is used in Visual SLAM?"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A) LiDAR"}),"\n",(0,i.jsx)(n.li,{children:"B) Camera"}),"\n",(0,i.jsx)(n.li,{children:"C) Ultrasonic"}),"\n",(0,i.jsx)(n.li,{children:"D) GPS"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Answer: B"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"What is the role of the Planner Server in Nav2?"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A) Control robot motors"}),"\n",(0,i.jsx)(n.li,{children:"B) Compute global path from start to goal"}),"\n",(0,i.jsx)(n.li,{children:"C) Detect obstacles"}),"\n",(0,i.jsx)(n.li,{children:"D) Save maps"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Answer: B"})}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Why is MPPI controller suitable for humanoids?"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"A) It's the fastest"}),"\n",(0,i.jsx)(n.li,{children:"B) It handles dynamic constraints and balance"}),"\n",(0,i.jsx)(n.li,{children:"C) It uses less CPU"}),"\n",(0,i.jsx)(n.li,{children:"D) It doesn't require sensors"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:"Answer: B"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,i.jsx)(n.p,{children:"In this chapter, we mastered Visual SLAM for localization and mapping using cameras. We configured the Nav2 stack for humanoid navigation, including costmaps, planners (A*, Dijkstra), and controllers (MPPI). We also explored behavior trees for complex navigation tasks. VSLAM and Nav2 are essential for autonomous humanoid robots operating in human environments."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Next Chapter"}),": We'll explore Vision-Language-Action (VLA) models, the cutting-edge approach that unifies perception, reasoning, and control."]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>o});var a=r(6540);const i={},s=a.createContext(i);function l(e){const n=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);